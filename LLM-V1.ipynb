{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:08:11.854302300Z",
     "start_time": "2023-11-20T00:08:11.808142300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adibv\\AppData\\Local\\Temp\\ipykernel_1304\\3520400249.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    },
    {
     "data": {
      "text/plain": "'NVIDIA GeForce GTX 1650 Ti'"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "torch.cuda.get_device_name(torch.cuda.device)\n",
    "\n",
    "\"\"\"\n",
    "1. Test different loss functions (ambrose, better weights)\n",
    "2. Test different models (like Temporal CNN, bigger linear model (keeping track of hyperparameters)\n",
    "3. Implement CAFA-Evaluator for better metrics\n",
    "4. Use more GOs in predictions\n",
    "5. Read Kaggle notebooks online to gain intuition\n",
    "6. Use new data!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cafa-5-protein-function-prediction.rar\n",
      "data/cafa-5-ems-2-embeddings-numpy\\test_embeddings.npy\n",
      "data/cafa-5-ems-2-embeddings-numpy\\test_ids.npy\n",
      "data/cafa-5-ems-2-embeddings-numpy\\train_embeddings.npy\n",
      "data/cafa-5-ems-2-embeddings-numpy\\train_ids.npy\n",
      "data/cafa-5-protein-function-prediction\\IA.txt\n",
      "data/cafa-5-protein-function-prediction\\sample_submission.tsv\n",
      "data/cafa-5-protein-function-prediction\\Test (Targets)\\testsuperset-taxon-list.tsv\n",
      "data/cafa-5-protein-function-prediction\\Test (Targets)\\testsuperset.fasta\n",
      "data/cafa-5-protein-function-prediction\\Train\\go-basic.obo\n",
      "data/cafa-5-protein-function-prediction\\Train\\train_sequences.fasta\n",
      "data/cafa-5-protein-function-prediction\\Train\\train_taxonomy.tsv\n",
      "data/cafa-5-protein-function-prediction\\Train\\train_terms.tsv\n",
      "data/protbert-embeddings-for-cafa5\\test_embeddings.npy\n",
      "data/protbert-embeddings-for-cafa5\\test_ids.npy\n",
      "data/protbert-embeddings-for-cafa5\\train_embeddings.npy\n",
      "data/protbert-embeddings-for-cafa5\\train_ids.npy\n",
      "data/t5embeds\\test_embeds.npy\n",
      "data/t5embeds\\test_ids.npy\n",
      "data/t5embeds\\train_embeds.npy\n",
      "data/t5embeds\\train_ids.npy\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = \"data/\"\n",
    "WORK_DIR = \"working/\"\n",
    "DATA_DIR = MAIN_DIR + \"cafa-5-protein-function-prediction\"\n",
    "PROTBERT_DIR = MAIN_DIR + \"protbert-embeddings-for-cafa5\"\n",
    "\n",
    "for dirname, _, filenames in os.walk(MAIN_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:08:11.855301800Z",
     "start_time": "2023-11-20T00:08:11.818674400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "    ProteinID       GO_ID  Probability\n0  A0A0A0MRZ7  GO:0000001        0.123\n1  A0A0A0MRZ7  GO:0000002        0.123\n2  A0A0A0MRZ8  GO:0000001        0.123\n3  A0A0A0MRZ8  GO:0000002        0.123\n4  A0A0A0MRZ9  GO:0000001        0.123\n5  A0A0A0MRZ9  GO:0000002        0.123\n6  A0A0A0MS00  GO:0000001        0.123\n7  A0A0A0MS00  GO:0000002        0.123\n8  A0A0A0MS01  GO:0000001        0.123\n9  A0A0A0MS01  GO:0000002        0.123",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ProteinID</th>\n      <th>GO_ID</th>\n      <th>Probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0A0MRZ7</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A0A0MRZ7</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A0A0MRZ8</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0A0MRZ8</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A0A0MRZ9</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A0A0A0MRZ9</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A0A0A0MS00</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A0A0A0MS00</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A0A0A0MS01</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A0A0A0MS01</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.tsv', sep='\\t', header=None)\n",
    "submission.columns = [\"ProteinID\", \"GO_ID\", \"Probability\"]\n",
    "submission.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:08:12.025875700Z",
     "start_time": "2023-11-20T00:08:11.827305300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda - NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    train_sequences_path = DATA_DIR  + \"/Train/train_sequences.fasta\"\n",
    "    train_labels_path = DATA_DIR + \"/Train/train_terms.tsv\"\n",
    "    test_sequences_path = DATA_DIR + \"/Test (Targets)/testsuperset.fasta\"\n",
    "\n",
    "    num_labels = 500\n",
    "    n_epochs = 25\n",
    "    batch_size = 128\n",
    "    lr = 0.002\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device} - {torch.cuda.get_device_name(device)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:08:12.026680Z",
     "start_time": "2023-11-20T00:08:12.013144700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# # ______________________ GET PROT BERT EMBEDDINGS WITH HUGGING FACE __________________________________\n",
    "#\n",
    "# # PROT BERT LOADING :\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "# model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to(config.device)\n",
    "#\n",
    "# def get_bert_embedding(\n",
    "#     sequence : str,\n",
    "#     len_seq_limit : int\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Function to collect last hidden state embedding vector from pre-trained ProtBERT Model\n",
    "#\n",
    "#     INPUTS:\n",
    "#     - sequence (str) : protein sequence (ex : AAABBB) from fasta file\n",
    "#     - len_seq_limit (int) : maximum sequence lenght (i.e nb of letters) for truncation\n",
    "#\n",
    "#     OUTPUTS:\n",
    "#     - output_hidden : last hidden state embedding vector for input sequence of length 1024\n",
    "#     \"\"\"\n",
    "#     sequence_w_spaces = ' '.join(list(sequence))\n",
    "#     encoded_input = tokenizer(\n",
    "#         sequence_w_spaces,\n",
    "#         truncation=True,\n",
    "#         max_length=len_seq_limit,\n",
    "#         padding='max_length',\n",
    "#         return_tensors='pt').to(config.device)\n",
    "#     output = model(**encoded_input)\n",
    "#     output_hidden = output['last_hidden_state'][:,0][0].detach().cpu().numpy()\n",
    "#     assert len(output_hidden)==1024\n",
    "#     return output_hidden\n",
    "#\n",
    "# ### COLLECTING FOR TRAIN SAMPLES :\n",
    "# print(\"Loading train set ProtBERT Embeddings...\")\n",
    "# fasta_train = SeqIO.parse(config.train_sequences_path, \"fasta\")\n",
    "# print(\"Total Nb of Elements : \", len(list(fasta_train)))\n",
    "# fasta_train = SeqIO.parse(config.train_sequences_path, \"fasta\")\n",
    "# ids_list = []\n",
    "# embed_vects_list = []\n",
    "# t0 = time.time()\n",
    "# checkpoint = 0\n",
    "# for item in tqdm(fasta_train):\n",
    "#     ids_list.append(item.id)\n",
    "#     embed_vects_list.append(\n",
    "#         get_bert_embedding(sequence = item.seq, len_seq_limit = 1200))\n",
    "#     checkpoint+=1\n",
    "#     if checkpoint>=100:\n",
    "#         df_res = pd.DataFrame(data={\"id\" : ids_list, \"embed_vect\" : embed_vects_list})\n",
    "#         np.save('/kaggle/working/train_ids.npy',np.array(ids_list))\n",
    "#         np.save('/kaggle/working/train_embeddings.npy',np.array(embed_vects_list))\n",
    "#         checkpoint=0\n",
    "#\n",
    "# np.save('/kaggle/working/train_ids.npy',np.array(ids_list))\n",
    "# np.save('/kaggle/working/train_embeddings.npy',np.array(embed_vects_list))\n",
    "# print('Total Elapsed Time:',time.time()-t0)\n",
    "#\n",
    "# ### COLLECTING FOR TEST SAMPLES :\n",
    "# print(\"Loading test set ProtBERT Embeddings...\")\n",
    "# fasta_test = SeqIO.parse(config.test_sequences_path, \"fasta\")\n",
    "# print(\"Total Nb of Elements : \", len(list(fasta_test)))\n",
    "# fasta_test = SeqIO.parse(config.test_sequences_path, \"fasta\")\n",
    "# ids_list = []\n",
    "# embed_vects_list = []\n",
    "# t0 = time.time()\n",
    "# checkpoint=0\n",
    "# for item in tqdm(fasta_test):\n",
    "#     ids_list.append(item.id)\n",
    "#     embed_vects_list.append(\n",
    "#         get_bert_embedding(sequence = item.seq, len_seq_limit = 1200))\n",
    "#     checkpoint+=1\n",
    "#     if checkpoint>=100:\n",
    "#         np.save('/kaggle/working/test_ids.npy',np.array(ids_list))\n",
    "#         np.save('/kaggle/working/test_embeddings.npy',np.array(embed_vects_list))\n",
    "#         checkpoint=0\n",
    "#\n",
    "# np.save('/kaggle/working/test_ids.npy',np.array(ids_list))\n",
    "# np.save('/kaggle/working/test_embeddings.npy',np.array(embed_vects_list))\n",
    "# print('Total Elasped Time:',time.time()-t0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:08:12.041679800Z",
     "start_time": "2023-11-20T00:08:12.025875700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE TARGETS FOR ENTRY IDS (500 MOST COMMON GO TERMS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "142246it [00:50, 2822.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATION FINISHED!\n"
     ]
    },
    {
     "data": {
      "text/plain": "      EntryID                                        labels_vect\n0      P20536  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...\n1      O73864  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...\n2      O95231  [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...\n3  A0A0B4J1F4  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...\n4      P54366  [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>labels_vect</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P20536</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>O73864</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>O95231</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0B4J1F4</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P54366</td>\n      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### SCRIPT FOR LABELS (TARGETS) VECTORS COLLECTING #####\n",
    "\n",
    "print(\"GENERATE TARGETS FOR ENTRY IDS (\"+str(config.num_labels)+\" MOST COMMON GO TERMS)\")\n",
    "ids = np.load(f\"{PROTBERT_DIR}/train_ids.npy\")\n",
    "labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n",
    "\n",
    "top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "labels_names = top_terms[:config.num_labels].index.values\n",
    "train_labels_sub = labels[(labels.term.isin(labels_names)) & (labels.EntryID.isin(ids))]\n",
    "id_labels = train_labels_sub.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
    "labels_matrix = np.empty((len(ids), len(labels_names)))\n",
    "\n",
    "for index, id in tqdm(enumerate(ids)):\n",
    "    id_gos_list = id_labels[id]\n",
    "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
    "    labels_matrix[index, temp] = 1\n",
    "\n",
    "labels_list = []\n",
    "for l in range(labels_matrix.shape[0]):\n",
    "    labels_list.append(labels_matrix[l, :])\n",
    "\n",
    "labels_df = pd.DataFrame(data={\"EntryID\":ids, \"labels_vect\":labels_list})\n",
    "labels_df.to_pickle(f\"{WORK_DIR}/train_targets_top\"+str(config.num_labels)+\".pkl\")\n",
    "print(\"GENERATION FINISHED!\")\n",
    "labels_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:09:14.320471600Z",
     "start_time": "2023-11-20T00:08:12.039676500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "term\nGO:0005575    92912\nGO:0008150    92210\nGO:0110165    91286\nGO:0003674    78637\nGO:0005622    70785\n              ...  \nGO:1900010        1\nGO:0039705        1\nGO:0039709        1\nGO:0039710        1\nGO:0044717        1\nName: EntryID, Length: 31466, dtype: int64"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T01:50:36.864276300Z",
     "start_time": "2023-11-20T01:50:36.846967400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "               GO    weight\n0      GO:0000001  0.000000\n1      GO:0000002  3.103836\n2      GO:0000003  3.439404\n3      GO:0000011  0.056584\n4      GO:0000012  6.400377\n...           ...       ...\n43243  GO:2001083  7.159871\n43244  GO:2001084  7.592457\n43245  GO:2001085  7.159871\n43246  GO:2001147  5.554589\n43247  GO:2001227  0.000000\n\n[43248 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GO</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GO:0000001</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GO:0000002</td>\n      <td>3.103836</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GO:0000003</td>\n      <td>3.439404</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GO:0000011</td>\n      <td>0.056584</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GO:0000012</td>\n      <td>6.400377</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43243</th>\n      <td>GO:2001083</td>\n      <td>7.159871</td>\n    </tr>\n    <tr>\n      <th>43244</th>\n      <td>GO:2001084</td>\n      <td>7.592457</td>\n    </tr>\n    <tr>\n      <th>43245</th>\n      <td>GO:2001085</td>\n      <td>7.159871</td>\n    </tr>\n    <tr>\n      <th>43246</th>\n      <td>GO:2001147</td>\n      <td>5.554589</td>\n    </tr>\n    <tr>\n      <th>43247</th>\n      <td>GO:2001227</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>43248 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GO_weight_dataset = pd.read_table(f'{DATA_DIR}/IA.txt', header=None, names=['GO', 'weight'])\n",
    "GO_weight_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T01:48:49.621599100Z",
     "start_time": "2023-11-20T01:48:49.570680300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0000e+00, 0.0000e+00, 2.5471e-02, 0.0000e+00, 3.6695e-01, 5.8919e-01,\n        5.8435e-01, 1.7165e-02, 4.5465e-01, 1.3480e-01, 4.1220e-01, 2.9561e-02,\n        2.5790e-01, 1.1533e+00, 7.8701e-02, 2.1213e-01, 1.5681e+00, 1.5985e+00,\n        1.6553e+00, 8.5186e-01, 1.6848e+00, 1.0687e-01, 6.7658e-02, 1.8248e+00,\n        1.6347e+00, 1.0367e-01, 3.1833e-01, 1.2295e-01, 4.9670e-01, 2.1570e+00,\n        1.6553e+00, 1.0337e+00, 7.3926e-02, 1.0960e+00, 1.5460e+00, 6.9622e-01,\n        3.2499e-01, 1.4971e-01, 4.3930e-01, 3.5163e-02, 2.4797e+00, 1.9149e+00,\n        0.0000e+00, 2.5399e+00, 1.8383e-04, 3.6778e-04, 1.3485e+00, 1.2932e-01,\n        3.5321e-01, 1.6135e-01, 1.0754e+00, 5.5739e-01, 4.0606e-01, 1.1151e+00,\n        3.0564e-01, 2.7477e+00, 5.9920e-01, 2.0041e-02, 3.4285e-02, 2.8116e+00,\n        1.0779e+00, 2.1543e+00, 1.0962e+00, 2.1763e+00, 1.2565e-01, 1.2376e+00,\n        2.5171e-01, 6.7157e-01, 2.4477e+00, 1.4801e+00, 7.9989e-01, 1.2116e+00,\n        8.1851e-02, 1.4936e+00, 1.7235e-02, 1.2501e+00, 3.4721e-01, 3.2024e-01,\n        1.5098e-02, 1.9369e+00, 3.0751e-01, 3.5565e-02, 3.6536e-01, 8.9766e-01,\n        4.1845e-02, 1.3596e+00, 3.2369e+00, 1.1825e-01, 2.0097e-01, 2.0182e-02,\n        6.5830e-01, 2.6372e-02, 2.0452e+00, 5.1553e-02, 9.7709e-03, 4.9917e-04,\n        2.9434e-02, 1.4150e-02, 3.4166e+00, 3.4394e+00, 1.0369e+00, 1.7331e+00,\n        2.0448e+00, 2.2686e+00, 7.8469e-01, 1.2833e+00, 2.2970e+00, 1.6828e+00,\n        1.0890e-01, 2.3202e+00, 2.4353e+00, 7.7336e-01, 3.8621e-02, 3.4291e-01,\n        8.1091e-02, 2.0510e+00, 2.0688e-02, 2.9382e+00, 6.8940e-01, 2.3982e-01,\n        1.8347e+00, 3.6919e+00, 2.1442e+00, 2.3057e-02, 3.6126e-02, 3.3458e-02,\n        3.7539e+00, 2.9282e-02, 1.1462e+00, 2.3666e+00, 1.4197e+00, 3.7907e-01,\n        3.8613e+00, 7.1186e-01, 2.3166e+00, 1.8144e+00, 2.3174e+00, 1.5362e+00,\n        1.4561e+00, 4.1617e-02, 0.0000e+00, 1.6080e-01, 3.8143e-03, 1.5573e+00,\n        3.0912e+00, 1.1125e+00, 1.3321e+00, 3.4071e+00, 1.5706e-01, 1.0290e+00,\n        1.4741e-01, 6.5866e-02, 2.0130e-01, 1.3653e-03, 6.6515e-02, 1.9866e-01,\n        2.2833e+00, 2.9354e+00, 1.2750e-01, 7.4752e-01, 1.9846e-03, 6.7243e-02,\n        3.7438e-02, 2.6380e+00, 5.1449e-01, 1.5174e+00, 4.3002e-01, 1.4084e-01,\n        1.0755e-01, 3.6987e-02, 7.6862e-01, 1.4098e+00, 6.2250e-01, 4.0477e+00,\n        4.2720e+00, 1.1373e-02, 9.1016e-01, 9.0739e-02, 3.1707e+00, 2.6335e-01,\n        2.0615e-02, 2.4115e+00, 2.4697e+00, 7.9520e-02, 1.7146e-01, 2.7155e+00,\n        4.8908e-01, 1.0126e-01, 8.3829e-02, 2.0742e+00, 4.3946e+00, 3.3400e-04,\n        1.6936e-01, 8.3113e-01, 6.8873e-01, 4.5477e-02, 1.7511e+00, 1.0822e-02,\n        4.7437e-02, 6.8326e-04, 6.9339e-01, 0.0000e+00, 3.4264e-04, 1.2888e+00,\n        1.9463e+00, 3.0051e-01, 1.5444e+00, 1.2550e+00, 1.0420e+00, 4.4902e+00,\n        3.9049e+00, 5.5715e-02, 1.9479e-01, 8.6857e-01, 3.6226e+00, 1.1281e+00,\n        5.3798e-01, 6.3596e-03, 1.5094e+00, 4.3666e+00, 4.3753e+00, 1.1958e-01,\n        3.9290e-01, 1.4000e+00, 7.3466e-01, 7.5386e-02, 1.4580e+00, 1.4801e-01,\n        5.2617e-01, 4.3177e-03, 2.2512e+00, 4.2164e-01, 9.0499e-01, 5.0131e-01,\n        6.9193e-01, 2.5853e+00, 1.4357e-01, 2.6029e+00, 2.4213e-01, 1.7957e-01,\n        3.2606e+00, 1.8589e+00, 2.0423e-01, 3.0411e+00, 4.7413e+00, 3.4150e-01,\n        5.9689e-02, 2.5957e+00, 8.9696e-01, 2.3805e-02, 3.0786e-01, 4.2013e+00,\n        1.0710e+00, 1.5658e-02, 1.0525e+00, 1.3898e+00, 3.3699e+00, 5.3278e-01,\n        3.5031e+00, 5.5638e-01, 2.0040e+00, 4.0944e-01, 1.5367e+00, 1.4568e-01,\n        3.7931e-01, 2.7781e+00, 4.8656e+00, 3.5506e+00, 2.5526e+00, 6.6680e-01,\n        4.7434e-01, 1.6130e-02, 3.2415e-03, 5.6221e-01, 4.2074e+00, 8.2085e-01,\n        7.4739e-01, 2.0153e-01, 5.8841e-01, 1.0211e+00, 9.4634e-04, 9.0913e-01,\n        0.0000e+00, 8.3795e-01, 4.7669e-04, 1.3885e+00, 3.7118e+00, 9.2383e-02,\n        1.8732e+00, 2.5000e+00, 3.2122e+00, 6.1731e-01, 4.9945e-01, 2.3380e+00,\n        2.5151e+00, 3.8030e-01, 1.8152e+00, 1.3597e-01, 3.3405e+00, 0.0000e+00,\n        2.5923e-02, 1.7056e+00, 4.7821e+00, 9.2288e-01, 4.0741e+00, 1.1470e-01,\n        1.8526e+00, 1.0477e+00, 4.7403e-01, 5.3402e-02, 8.5637e-01, 2.8549e-02,\n        1.1147e-01, 1.2343e+00, 6.1940e-03, 1.0826e-02, 3.6066e+00, 4.0384e-01,\n        1.6353e+00, 1.6396e-01, 2.4161e+00, 2.7015e-01, 1.0774e+00, 1.1942e+00,\n        3.1732e-02, 6.7965e-01, 7.0929e-01, 8.3793e-02, 2.6338e+00, 4.4208e+00,\n        1.3845e+00, 2.0613e+00, 7.4082e-02, 2.4349e-01, 6.0416e-01, 8.9913e-01,\n        1.0256e-01, 7.8809e-01, 1.7777e+00, 5.3084e-02, 5.7430e-01, 2.1903e-01,\n        6.8298e-01, 4.3794e+00, 2.7641e+00, 8.5239e-01, 2.6653e-01, 7.5159e-01,\n        5.1975e+00, 6.7901e-01, 4.6250e+00, 6.2370e-01, 8.6425e-01, 2.6055e+00,\n        3.5145e-03, 5.5883e-02, 1.2121e+00, 3.1436e+00, 1.5877e-02, 1.9418e+00,\n        2.8429e+00, 4.0229e+00, 6.0000e-04, 1.5435e-01, 4.4906e-01, 3.8233e+00,\n        1.7159e+00, 6.4212e-01, 1.3997e+00, 6.7475e-01, 0.0000e+00, 4.0579e+00,\n        7.9647e-01, 8.3161e-01, 0.0000e+00, 1.3006e-02, 2.7474e-01, 0.0000e+00,\n        4.0436e-01, 1.1242e-02, 2.6868e-01, 8.0555e-01, 0.0000e+00, 1.7791e-01,\n        0.0000e+00, 1.6408e+00, 1.2841e-02, 2.2937e+00, 1.3595e-02, 4.6978e+00,\n        8.1119e-01, 5.7619e-01, 3.5256e+00, 3.4713e+00, 1.3121e-03, 5.8276e-01,\n        2.5950e-01, 3.6567e+00, 2.1710e+00, 6.5534e-01, 3.1508e+00, 1.1657e+00,\n        1.8088e-02, 7.6756e-01, 4.4897e+00, 3.9764e-01, 9.6775e-01, 9.4361e-01,\n        3.9841e-01, 5.4337e+00, 1.2637e+00, 4.8673e+00, 0.0000e+00, 2.5935e+00,\n        2.2530e+00, 3.0094e-01, 1.8589e-02, 2.4346e-01, 4.0300e-01, 1.4036e-01,\n        4.7880e-01, 0.0000e+00, 1.1336e+00, 8.8702e-01, 1.1215e+00, 5.5073e+00,\n        1.0897e-01, 3.1001e-01, 5.3321e-02, 4.6152e+00, 4.3832e-02, 6.7543e-01,\n        1.1304e+00, 1.4258e-02, 7.2500e-01, 9.3642e-01, 5.5850e-01, 2.5215e-01,\n        0.0000e+00, 1.9226e-01, 1.1862e-01, 2.5114e-01, 3.9269e+00, 1.9060e-01,\n        4.6815e-03, 1.2477e-02, 3.3507e-01, 8.5376e-01, 3.4522e-01, 2.3450e-01,\n        2.9355e+00, 3.0824e-01, 1.8217e-02, 4.8280e-01, 1.8697e+00, 1.5576e+00,\n        1.2618e+00, 4.9878e-01, 2.0099e-02, 5.1090e+00, 3.2457e-03, 9.6321e-02,\n        1.4334e+00, 1.5491e-02, 3.3970e+00, 3.5744e-02, 5.0228e-02, 2.6565e-01,\n        2.0113e+00, 1.1452e-01, 1.0675e+00, 1.4540e+00, 6.7341e-02, 1.2733e-01,\n        3.3338e-03, 1.8839e+00, 3.0579e+00, 2.5267e+00, 1.3972e-01, 1.3959e+00,\n        2.9233e+00, 8.4393e-04, 9.9320e-01, 3.3551e-01, 2.7208e+00, 8.9730e-02,\n        2.1993e+00, 9.3109e-02, 7.1707e-01, 3.4747e+00, 5.5782e+00, 5.7978e+00,\n        8.7809e-03, 5.0230e+00, 9.0242e-01, 2.0637e+00, 4.0077e-02, 3.9558e+00,\n        2.9160e-01, 3.0832e+00])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GO_weights = []\n",
    "\n",
    "for each_label in labels_names:\n",
    "    GO_weights.append(GO_weight_dataset.loc[GO_with_weights['GO'] == each_label]['weight'].values[0])\n",
    "\n",
    "GO_weights = torch.tensor(GO_weights, dtype=torch.float32)\n",
    "GO_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:10:31.483569100Z",
     "start_time": "2023-11-20T00:10:29.134684700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Directories for the different embedding vectors :\n",
    "embeds_map = {\n",
    "    \"T5\" : \"t5embeds\",\n",
    "    \"ProtBERT\" : \"protbert-embeddings-for-cafa5\",\n",
    "    \"EMS2\" : \"cafa-5-ems-2-embeddings-numpy\"\n",
    "}\n",
    "\n",
    "# Length of the different embedding vectors :\n",
    "embeds_dim = {\n",
    "    \"T5\" : 1024,\n",
    "    \"ProtBERT\" : 1024,\n",
    "    \"EMS2\" : 1280\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:09:16.560461900Z",
     "start_time": "2023-11-20T00:09:16.557082900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "      EntryID                                              embed  \\\n0      P20536  [0.04948842525482178, -0.03293515741825104, 0....   \n1      O73864  [-0.04461636394262314, 0.06492499262094498, -0...   \n2      O95231  [-0.02012803591787815, -0.04977943375706673, 0...   \n3  A0A0B4J1F4  [-0.00751461973413825, 0.06062775477766991, 0....   \n4      P54366  [0.013468174263834953, 0.04151567816734314, 0....   \n5      P33681  [0.001116646104492247, -0.01536268275231123, 0...   \n6      P77596  [0.03678780049085617, 0.052980050444602966, 0....   \n7      Q16787  [0.007108339574187994, 0.01562744379043579, 0....   \n8      Q59VP0  [-0.006104866974055767, -0.026720179244875908,...   \n9      P13508  [-0.0071898759342730045, -0.02323203906416893,...   \n\n                                         labels_vect  \n0  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...  \n1  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...  \n2  [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...  \n3  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...  \n4  [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...  \n5  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n6  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n7  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...  \n8  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n9  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>embed</th>\n      <th>labels_vect</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P20536</td>\n      <td>[0.04948842525482178, -0.03293515741825104, 0....</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>O73864</td>\n      <td>[-0.04461636394262314, 0.06492499262094498, -0...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>O95231</td>\n      <td>[-0.02012803591787815, -0.04977943375706673, 0...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0B4J1F4</td>\n      <td>[-0.00751461973413825, 0.06062775477766991, 0....</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P54366</td>\n      <td>[0.013468174263834953, 0.04151567816734314, 0....</td>\n      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>P33681</td>\n      <td>[0.001116646104492247, -0.01536268275231123, 0...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>P77596</td>\n      <td>[0.03678780049085617, 0.052980050444602966, 0....</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Q16787</td>\n      <td>[0.007108339574187994, 0.01562744379043579, 0....</td>\n      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Q59VP0</td>\n      <td>[-0.006104866974055767, -0.026720179244875908,...</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>P13508</td>\n      <td>[-0.0071898759342730045, -0.02323203906416893,...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ProteinSequenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datatype, embeddings_source):\n",
    "        super(ProteinSequenceDataset).__init__()\n",
    "        self.datatype = datatype\n",
    "\n",
    "        if embeddings_source in [\"ProtBERT\", \"EMS2\"]:\n",
    "            embeds = np.load(f\"{MAIN_DIR}\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeddings.npy\")\n",
    "            ids = np.load(f\"{MAIN_DIR}/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n",
    "\n",
    "        if embeddings_source == \"T5\":\n",
    "            embeds = np.load(f\"{MAIN_DIR}/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeds.npy\")\n",
    "            ids = np.load(f\"{MAIN_DIR}/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n",
    "\n",
    "        embeds_list = []\n",
    "        for l in range(embeds.shape[0]):\n",
    "            embeds_list.append(embeds[l,:])\n",
    "        self.df = pd.DataFrame(data={\"EntryID\": ids, \"embed\" : embeds_list})\n",
    "\n",
    "        if datatype==\"train\":\n",
    "            df_labels = pd.read_pickle(\n",
    "                f\"{WORK_DIR}/train_targets_top\"+str(config.num_labels)+\".pkl\")\n",
    "            self.df = self.df.merge(df_labels, on=\"EntryID\")\\\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        embed = torch.tensor(self.df.iloc[index][\"embed\"], dtype=torch.float32)\n",
    "\n",
    "        if self.datatype==\"train\":\n",
    "            targets = torch.tensor(self.df.iloc[index][\"labels_vect\"], dtype=torch.float32)\n",
    "            return embed, targets\n",
    "\n",
    "        if self.datatype==\"test\":\n",
    "            id = self.df.iloc[index][\"EntryID\"]\n",
    "            return embed, id\n",
    "\n",
    "\n",
    "dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source=\"T5\")\n",
    "dataset.df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:09:18.905460300Z",
     "start_time": "2023-11-20T00:09:16.570460Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPONENTS FOR FIRST PROTEIN:  \n",
      "EMBEDDINGS VECTOR: \n",
      "  tensor([ 0.0495, -0.0329,  0.0325,  ..., -0.0435,  0.0965,  0.0731]) \n",
      "\n",
      "TARGETS LABELS VECTOR: \n",
      "  tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings, labels = dataset.__getitem__(0)\n",
    "print(\"COMPONENTS FOR FIRST PROTEIN:  \")\n",
    "print(\"EMBEDDINGS VECTOR: \\n \", embeddings, \"\\n\")\n",
    "print(\"TARGETS LABELS VECTOR: \\n \", labels, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:09:19.051361900Z",
     "start_time": "2023-11-20T00:09:18.909460900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_dim, input_dim)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 1000)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(1000, 800)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(800, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:09:19.052321600Z",
     "start_time": "2023-11-20T00:09:18.997319200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        # (batch_size, channels, embed_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, dilation=1, padding=1, stride=1)\n",
    "        # (batch_size, 3, embed_size)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # (batch_size, 3, embed_size/2 = 512)\n",
    "        self.conv2 = nn.Conv1d(in_channels=3, out_channels=8, kernel_size=3, dilation=1, padding=1, stride=1)\n",
    "        # (batch_size, 8, embed_size/2 = 512)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # (batch_size, 8, embed_size/4 = 256)\n",
    "        self.fc1 = nn.Linear(in_features=int(8 * input_dim/4), out_features=1024)       # 1024 is better\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=num_classes)                # 1024 is better\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:09:19.052321600Z",
     "start_time": "2023-11-20T00:09:18.997319200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def train_model(embeddings_source, model_type=\"linear\", train_size=0.9):\n",
    "\n",
    "    train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n",
    "\n",
    "    train_set, val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    if model_type == \"linear\":\n",
    "        model = MultiLayerPerceptron(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "    if model_type == \"conv\":\n",
    "        model = CNN1D(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n",
    "    MultiLabelLoss = torch.nn.BCEWithLogitsLoss(weight=GO_weights.to(config.device))\n",
    "    f1_score = MultilabelF1Score(num_labels=config.num_labels).to(config.device)\n",
    "    n_epochs = config.n_epochs\n",
    "\n",
    "    print(\"BEGIN TRAINING...\")\n",
    "    train_loss_history=[]\n",
    "    val_loss_history=[]\n",
    "\n",
    "    train_f1score_history=[]\n",
    "    val_f1score_history=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"EPOCH \", epoch+1)\n",
    "\n",
    "        ## TRAIN PHASE :\n",
    "        losses, scores = [], []\n",
    "\n",
    "        for embed, targets in tqdm(train_dataloader):\n",
    "            embed, targets = embed.to(config.device), targets.to(config.device)\n",
    "            preds = model(embed)\n",
    "            loss= MultiLabelLoss(preds, targets)\n",
    "\n",
    "            score=f1_score(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            scores.append(score.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"Running Average TRAIN Loss : \", avg_loss)\n",
    "        print(\"Running Average TRAIN F1-Score : \", avg_score)\n",
    "        train_loss_history.append(avg_loss)\n",
    "        train_f1score_history.append(avg_score)\n",
    "\n",
    "        ## VALIDATION PHASE :\n",
    "        losses, scores = [], []\n",
    "\n",
    "        for embed, targets in val_dataloader:\n",
    "            embed, targets = embed.to(config.device), targets.to(config.device)\n",
    "            preds = model(embed)\n",
    "\n",
    "            loss= MultiLabelLoss(preds, targets)\n",
    "            score=f1_score(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            scores.append(score.item())\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"Running Average VAL Loss : \", avg_loss)\n",
    "        print(\"Running Average VAL F1-Score : \", avg_score)\n",
    "        val_loss_history.append(avg_loss)\n",
    "        val_f1score_history.append(avg_score)\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(\"TRAINING FINISHED\")\n",
    "    print(\"FINAL TRAINING SCORE : \", train_f1score_history[-1])\n",
    "    print(\"FINAL VALIDATION SCORE : \", val_f1score_history[-1])\n",
    "\n",
    "    losses_history = {\"train\" : train_loss_history, \"val\" : val_loss_history}\n",
    "    scores_history = {\"train\" : train_f1score_history, \"val\" : val_f1score_history}\n",
    "\n",
    "    return model, losses_history, scores_history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:10:53.309443800Z",
     "start_time": "2023-11-20T00:10:53.283923500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN TRAINING...\n",
      "EPOCH  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:38<00:00, 26.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.14626838810198553\n",
      "Running Average TRAIN F1-Score :  0.04428508663391852\n",
      "Running Average VAL Loss :  0.13415391696617007\n",
      "Running Average VAL F1-Score :  0.07087949490440744\n",
      "\n",
      "\n",
      "EPOCH  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.12974025100677997\n",
      "Running Average TRAIN F1-Score :  0.09059316988338481\n",
      "Running Average VAL Loss :  0.12943011076588715\n",
      "Running Average VAL F1-Score :  0.10814577939787082\n",
      "\n",
      "\n",
      "EPOCH  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.12492420246729723\n",
      "Running Average TRAIN F1-Score :  0.11745217273553292\n",
      "Running Average VAL Loss :  0.1263012649225337\n",
      "Running Average VAL F1-Score :  0.11495284396888954\n",
      "\n",
      "\n",
      "EPOCH  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.12081461632019513\n",
      "Running Average TRAIN F1-Score :  0.14048802414974132\n",
      "Running Average VAL Loss :  0.12476456152009112\n",
      "Running Average VAL F1-Score :  0.1318848884797522\n",
      "\n",
      "\n",
      "EPOCH  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:35<00:00, 28.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11720933650548641\n",
      "Running Average TRAIN F1-Score :  0.1617087425959932\n",
      "Running Average VAL Loss :  0.1229143424092659\n",
      "Running Average VAL F1-Score :  0.15749583007501705\n",
      "\n",
      "\n",
      "EPOCH  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11366677759112892\n",
      "Running Average TRAIN F1-Score :  0.1833227827370941\n",
      "Running Average VAL Loss :  0.1224772527015635\n",
      "Running Average VAL F1-Score :  0.17120778261284744\n",
      "\n",
      "\n",
      "EPOCH  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11034545358958897\n",
      "Running Average TRAIN F1-Score :  0.2050083539300746\n",
      "Running Average VAL Loss :  0.12262508133426309\n",
      "Running Average VAL F1-Score :  0.16778317955322564\n",
      "\n",
      "\n",
      "EPOCH  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.10707097929287386\n",
      "Running Average TRAIN F1-Score :  0.2260847698737096\n",
      "Running Average VAL Loss :  0.12145680661446281\n",
      "Running Average VAL F1-Score :  0.1962526811153761\n",
      "\n",
      "\n",
      "EPOCH  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.10407097927935711\n",
      "Running Average TRAIN F1-Score :  0.24598436297236623\n",
      "Running Average VAL Loss :  0.12215054939900126\n",
      "Running Average VAL F1-Score :  0.20112482930666634\n",
      "\n",
      "\n",
      "EPOCH  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:35<00:00, 28.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.10128915519802482\n",
      "Running Average TRAIN F1-Score :  0.2653060683480033\n",
      "Running Average VAL Loss :  0.12265120932300176\n",
      "Running Average VAL F1-Score :  0.22389395801084383\n",
      "\n",
      "\n",
      "EPOCH  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09221877809706983\n",
      "Running Average TRAIN F1-Score :  0.31032411070106986\n",
      "Running Average VAL Loss :  0.12143167327823383\n",
      "Running Average VAL F1-Score :  0.23710714892617293\n",
      "\n",
      "\n",
      "EPOCH  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:35<00:00, 27.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09007727240140621\n",
      "Running Average TRAIN F1-Score :  0.3266248246589741\n",
      "Running Average VAL Loss :  0.12149704567023686\n",
      "Running Average VAL F1-Score :  0.2347098027489015\n",
      "\n",
      "\n",
      "EPOCH  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.0890112217817154\n",
      "Running Average TRAIN F1-Score :  0.3330147443534611\n",
      "Running Average VAL Loss :  0.12251759094319173\n",
      "Running Average VAL F1-Score :  0.23861480357923678\n",
      "\n",
      "\n",
      "EPOCH  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08748150450157953\n",
      "Running Average TRAIN F1-Score :  0.34153592050611437\n",
      "Running Average VAL Loss :  0.12241831455113632\n",
      "Running Average VAL F1-Score :  0.2417687845549413\n",
      "\n",
      "\n",
      "EPOCH  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08728252749491881\n",
      "Running Average TRAIN F1-Score :  0.3419895744496411\n",
      "Running Average VAL Loss :  0.12197084724903107\n",
      "Running Average VAL F1-Score :  0.2408410553554339\n",
      "\n",
      "\n",
      "EPOCH  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08706715705987814\n",
      "Running Average TRAIN F1-Score :  0.34177587355499145\n",
      "Running Average VAL Loss :  0.1221739320483591\n",
      "Running Average VAL F1-Score :  0.24383732583373785\n",
      "\n",
      "\n",
      "EPOCH  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.0870818231221322\n",
      "Running Average TRAIN F1-Score :  0.34352206204321\n",
      "Running Average VAL Loss :  0.12203066310446177\n",
      "Running Average VAL F1-Score :  0.24273820527430093\n",
      "\n",
      "\n",
      "EPOCH  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08709761914197024\n",
      "Running Average TRAIN F1-Score :  0.343285358571387\n",
      "Running Average VAL Loss :  0.12192961181114827\n",
      "Running Average VAL F1-Score :  0.2433486438489386\n",
      "\n",
      "\n",
      "EPOCH  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08703718555497598\n",
      "Running Average TRAIN F1-Score :  0.34419171321582603\n",
      "Running Average VAL Loss :  0.122039580983775\n",
      "Running Average VAL F1-Score :  0.24392280481489642\n",
      "\n",
      "\n",
      "EPOCH  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08703083844927999\n",
      "Running Average TRAIN F1-Score :  0.34290862623062524\n",
      "Running Average VAL Loss :  0.12235397905377406\n",
      "Running Average VAL F1-Score :  0.2425440797981407\n",
      "\n",
      "\n",
      "EPOCH  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.0870434294169123\n",
      "Running Average TRAIN F1-Score :  0.3441138860884008\n",
      "Running Average VAL Loss :  0.12189124105498195\n",
      "Running Average VAL F1-Score :  0.24299195116119726\n",
      "\n",
      "\n",
      "EPOCH  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:35<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08704494079435383\n",
      "Running Average TRAIN F1-Score :  0.34393068475204036\n",
      "Running Average VAL Loss :  0.12242660491860338\n",
      "Running Average VAL F1-Score :  0.24439877777227334\n",
      "\n",
      "\n",
      "EPOCH  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08702752962857337\n",
      "Running Average TRAIN F1-Score :  0.34342328197770305\n",
      "Running Average VAL Loss :  0.12187290896794625\n",
      "Running Average VAL F1-Score :  0.24500832839735917\n",
      "\n",
      "\n",
      "EPOCH  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08707654158343801\n",
      "Running Average TRAIN F1-Score :  0.34350915567262785\n",
      "Running Average VAL Loss :  0.12277868529781699\n",
      "Running Average VAL F1-Score :  0.24247935261311276\n",
      "\n",
      "\n",
      "EPOCH  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:36<00:00, 27.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.08704605338337658\n",
      "Running Average TRAIN F1-Score :  0.34369529249308467\n",
      "Running Average VAL Loss :  0.12216846997450505\n",
      "Running Average VAL F1-Score :  0.24323299606995924\n",
      "\n",
      "\n",
      "TRAINING FINISHED\n",
      "FINAL TRAINING SCORE :  0.34369529249308467\n",
      "FINAL VALIDATION SCORE :  0.24323299606995924\n"
     ]
    }
   ],
   "source": [
    "t5_model, t5_losses, t5_scores = train_model(embeddings_source=\"T5\", model_type=\"linear\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T00:27:53.482560700Z",
     "start_time": "2023-11-20T00:10:56.046650800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t5_model(dataset[0][0].reshape(1, -1).to(config.device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(embeddings_source):\n",
    "    test_dataset = ProteinSequenceDataset(datatype=\"test\", embeddings_source = embeddings_source)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    if embeddings_source == \"T5\":\n",
    "        model = t5_model\n",
    "    if embeddings_source == \"ProtBERT\":\n",
    "        model = protbert_model\n",
    "    if embeddings_source == \"EMS2\":\n",
    "        model = ems2_model\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n",
    "    top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "    labels_names = top_terms[:config.num_labels].index.values\n",
    "    print(\"GENERATE PREDICTION FOR TEST SET...\")\n",
    "\n",
    "    ids_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n",
    "    go_terms_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n",
    "    confs_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=np.float32)\n",
    "\n",
    "    for i, (embed, id) in tqdm(enumerate(test_dataloader)):\n",
    "        embed = embed.to(config.device)\n",
    "        confs_[i*config.num_labels:(i+1)*config.num_labels] = torch.nn.functional.sigmoid(model(embed)).squeeze().detach().cpu().numpy()\n",
    "        ids_[i*config.num_labels:(i+1)*config.num_labels] = id[0]\n",
    "        go_terms_[i*config.num_labels:(i+1)*config.num_labels] = labels_names\n",
    "\n",
    "    submission_df = pd.DataFrame(data={\"Id\" : ids_, \"GO term\" : go_terms_, \"Confidence\" : confs_})\n",
    "    print(\"PREDICTIONS DONE\")\n",
    "    return submission_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_df = predict(\"T5\")\n",
    "submission_df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Linear_Lightning(pl.LightningModule):\n",
    "    def __init__(self, input_dim, num_classes, train_size, **hparams):\n",
    "        super(Linear_Lightning, self).__init__()\n",
    "\n",
    "        self.model = MultiLayerPerceptron(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "        train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n",
    "        self.train_set, self.val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n",
    "\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "\n",
    "        self.f1_score = MultilabelF1Score(num_labels=num_classes)\n",
    "        self.accuracy = MultilabelAccuracy(num_labels=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        embed, targets = batch\n",
    "        preds = self(embed)\n",
    "        loss = self.loss_fn(preds, targets)\n",
    "        f1_score = self.f1_score(preds, targets)\n",
    "        acc_score = self.accuracy(preds, targets)\n",
    "\n",
    "        logs = {\"train_loss\" : loss, \"f1_score\" : f1_score, \"accuracy_score\" : acc_score}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"log\": logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        embed, targets = batch\n",
    "        preds = self(embed)\n",
    "        loss= self.loss_fn(preds, targets)\n",
    "        f1_score = self.f1_score(preds, targets)\n",
    "        acc_score = self.accuracy(preds, targets)\n",
    "\n",
    "        return {\"val_loss\": loss, \"f1_score\": f1_score, \"accuracy_score\": acc_score}\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in ouputs]).mean()\n",
    "        logs = {\"val_loss\" : avg_loss}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"avg_val_loss\": avg_loss, \"log\": logs}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataloader = torch.utils.data.DataLoader(self.val_set, batch_size=config.batch_size, shuffle=False,)\n",
    "        return val_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataloader = torch.utils.data.DataLoader(self.train_set, batch_size=self.batch_size, shuffle=False)\n",
    "        return train_dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=config.n_epochs,\n",
    "    limit_train_batches=5000,\n",
    "    logger=logger)\n",
    "\n",
    "model = Linear_Lightning(\n",
    "    input_dim=embeds_dim[embeddings_source],\n",
    "    num_classes=config.num_labels,\n",
    "    train_size=0.8\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
