{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:03:16.348596300Z",
     "start_time": "2023-11-13T00:03:04.236815600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adibv\\AppData\\Local\\Temp\\ipykernel_39696\\3520400249.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "C:\\Users\\adibv\\.conda\\envs\\light\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "'NVIDIA GeForce GTX 1650 Ti'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "torch.cuda.get_device_name(torch.cuda.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cafa-5-ems-2-embeddings-numpy\\test_embeddings.npy\n",
      "data/cafa-5-ems-2-embeddings-numpy\\test_ids.npy\n",
      "data/cafa-5-ems-2-embeddings-numpy\\train_embeddings.npy\n",
      "data/cafa-5-ems-2-embeddings-numpy\\train_ids.npy\n",
      "data/cafa-5-protein-function-prediction\\IA.txt\n",
      "data/cafa-5-protein-function-prediction\\sample_submission.tsv\n",
      "data/cafa-5-protein-function-prediction\\Test (Targets)\\testsuperset-taxon-list.tsv\n",
      "data/cafa-5-protein-function-prediction\\Test (Targets)\\testsuperset.fasta\n",
      "data/cafa-5-protein-function-prediction\\Train\\go-basic.obo\n",
      "data/cafa-5-protein-function-prediction\\Train\\train_sequences.fasta\n",
      "data/cafa-5-protein-function-prediction\\Train\\train_taxonomy.tsv\n",
      "data/cafa-5-protein-function-prediction\\Train\\train_terms.tsv\n",
      "data/protbert-embeddings-for-cafa5\\test_embeddings.npy\n",
      "data/protbert-embeddings-for-cafa5\\test_ids.npy\n",
      "data/protbert-embeddings-for-cafa5\\train_embeddings.npy\n",
      "data/protbert-embeddings-for-cafa5\\train_ids.npy\n",
      "data/t5embeds\\test_embeds.npy\n",
      "data/t5embeds\\test_ids.npy\n",
      "data/t5embeds\\train_embeds.npy\n",
      "data/t5embeds\\train_ids.npy\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = \"data/\"\n",
    "WORK_DIR = \"working/\"\n",
    "DATA_DIR = MAIN_DIR + \"cafa-5-protein-function-prediction\"\n",
    "PROTBERT_DIR = MAIN_DIR + \"protbert-embeddings-for-cafa5\"\n",
    "\n",
    "for dirname, _, filenames in os.walk(MAIN_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:03:16.354992Z",
     "start_time": "2023-11-13T00:03:16.349599200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    ProteinID       GO_ID  Probability\n0  A0A0A0MRZ7  GO:0000001        0.123\n1  A0A0A0MRZ7  GO:0000002        0.123\n2  A0A0A0MRZ8  GO:0000001        0.123\n3  A0A0A0MRZ8  GO:0000002        0.123\n4  A0A0A0MRZ9  GO:0000001        0.123\n5  A0A0A0MRZ9  GO:0000002        0.123\n6  A0A0A0MS00  GO:0000001        0.123\n7  A0A0A0MS00  GO:0000002        0.123\n8  A0A0A0MS01  GO:0000001        0.123\n9  A0A0A0MS01  GO:0000002        0.123",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ProteinID</th>\n      <th>GO_ID</th>\n      <th>Probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0A0MRZ7</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A0A0MRZ7</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A0A0MRZ8</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0A0MRZ8</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A0A0MRZ9</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A0A0A0MRZ9</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A0A0A0MS00</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A0A0A0MS00</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A0A0A0MS01</td>\n      <td>GO:0000001</td>\n      <td>0.123</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A0A0A0MS01</td>\n      <td>GO:0000002</td>\n      <td>0.123</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.tsv', sep='\\t', header=None)\n",
    "submission.columns = [\"ProteinID\", \"GO_ID\", \"Probability\"]\n",
    "submission.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:03:16.532074300Z",
     "start_time": "2023-11-13T00:03:16.356992500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda - NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    train_sequences_path = DATA_DIR  + \"/Train/train_sequences.fasta\"\n",
    "    train_labels_path = DATA_DIR + \"/Train/train_terms.tsv\"\n",
    "    test_sequences_path = DATA_DIR + \"/Test (Targets)/testsuperset.fasta\"\n",
    "\n",
    "    num_labels = 500\n",
    "    n_epochs = 25\n",
    "    batch_size = 128\n",
    "    lr = 0.002\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Device: {device} - {torch.cuda.get_device_name(device)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:11:24.648628300Z",
     "start_time": "2023-11-13T00:11:24.607631300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ______________________ GET PROT BERT EMBEDDINGS WITH HUGGING FACE __________________________________\n",
    "#\n",
    "# # PROT BERT LOADING :\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "# model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to(config.device)\n",
    "#\n",
    "# def get_bert_embedding(\n",
    "#     sequence : str,\n",
    "#     len_seq_limit : int\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Function to collect last hidden state embedding vector from pre-trained ProtBERT Model\n",
    "#\n",
    "#     INPUTS:\n",
    "#     - sequence (str) : protein sequence (ex : AAABBB) from fasta file\n",
    "#     - len_seq_limit (int) : maximum sequence lenght (i.e nb of letters) for truncation\n",
    "#\n",
    "#     OUTPUTS:\n",
    "#     - output_hidden : last hidden state embedding vector for input sequence of length 1024\n",
    "#     \"\"\"\n",
    "#     sequence_w_spaces = ' '.join(list(sequence))\n",
    "#     encoded_input = tokenizer(\n",
    "#         sequence_w_spaces,\n",
    "#         truncation=True,\n",
    "#         max_length=len_seq_limit,\n",
    "#         padding='max_length',\n",
    "#         return_tensors='pt').to(config.device)\n",
    "#     output = model(**encoded_input)\n",
    "#     output_hidden = output['last_hidden_state'][:,0][0].detach().cpu().numpy()\n",
    "#     assert len(output_hidden)==1024\n",
    "#     return output_hidden\n",
    "#\n",
    "# ### COLLECTING FOR TRAIN SAMPLES :\n",
    "# print(\"Loading train set ProtBERT Embeddings...\")\n",
    "# fasta_train = SeqIO.parse(config.train_sequences_path, \"fasta\")\n",
    "# print(\"Total Nb of Elements : \", len(list(fasta_train)))\n",
    "# fasta_train = SeqIO.parse(config.train_sequences_path, \"fasta\")\n",
    "# ids_list = []\n",
    "# embed_vects_list = []\n",
    "# t0 = time.time()\n",
    "# checkpoint = 0\n",
    "# for item in tqdm(fasta_train):\n",
    "#     ids_list.append(item.id)\n",
    "#     embed_vects_list.append(\n",
    "#         get_bert_embedding(sequence = item.seq, len_seq_limit = 1200))\n",
    "#     checkpoint+=1\n",
    "#     if checkpoint>=100:\n",
    "#         df_res = pd.DataFrame(data={\"id\" : ids_list, \"embed_vect\" : embed_vects_list})\n",
    "#         np.save('/kaggle/working/train_ids.npy',np.array(ids_list))\n",
    "#         np.save('/kaggle/working/train_embeddings.npy',np.array(embed_vects_list))\n",
    "#         checkpoint=0\n",
    "#\n",
    "# np.save('/kaggle/working/train_ids.npy',np.array(ids_list))\n",
    "# np.save('/kaggle/working/train_embeddings.npy',np.array(embed_vects_list))\n",
    "# print('Total Elapsed Time:',time.time()-t0)\n",
    "#\n",
    "# ### COLLECTING FOR TEST SAMPLES :\n",
    "# print(\"Loading test set ProtBERT Embeddings...\")\n",
    "# fasta_test = SeqIO.parse(config.test_sequences_path, \"fasta\")\n",
    "# print(\"Total Nb of Elements : \", len(list(fasta_test)))\n",
    "# fasta_test = SeqIO.parse(config.test_sequences_path, \"fasta\")\n",
    "# ids_list = []\n",
    "# embed_vects_list = []\n",
    "# t0 = time.time()\n",
    "# checkpoint=0\n",
    "# for item in tqdm(fasta_test):\n",
    "#     ids_list.append(item.id)\n",
    "#     embed_vects_list.append(\n",
    "#         get_bert_embedding(sequence = item.seq, len_seq_limit = 1200))\n",
    "#     checkpoint+=1\n",
    "#     if checkpoint>=100:\n",
    "#         np.save('/kaggle/working/test_ids.npy',np.array(ids_list))\n",
    "#         np.save('/kaggle/working/test_embeddings.npy',np.array(embed_vects_list))\n",
    "#         checkpoint=0\n",
    "#\n",
    "# np.save('/kaggle/working/test_ids.npy',np.array(ids_list))\n",
    "# np.save('/kaggle/working/test_embeddings.npy',np.array(embed_vects_list))\n",
    "# print('Total Elasped Time:',time.time()-t0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE TARGETS FOR ENTRY IDS (500 MOST COMMON GO TERMS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "142246it [00:37, 3829.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATION FINISHED!\n"
     ]
    },
    {
     "data": {
      "text/plain": "      EntryID                                        labels_vect\n0      P20536  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...\n1      O73864  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...\n2      O95231  [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...\n3  A0A0B4J1F4  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...\n4      P54366  [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>labels_vect</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P20536</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>O73864</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>O95231</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0B4J1F4</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P54366</td>\n      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### SCRIPT FOR LABELS (TARGETS) VECTORS COLLECTING #####\n",
    "\n",
    "print(\"GENERATE TARGETS FOR ENTRY IDS (\"+str(config.num_labels)+\" MOST COMMON GO TERMS)\")\n",
    "ids = np.load(f\"{PROTBERT_DIR}/train_ids.npy\")\n",
    "labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n",
    "\n",
    "top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "labels_names = top_terms[:config.num_labels].index.values\n",
    "train_labels_sub = labels[(labels.term.isin(labels_names)) & (labels.EntryID.isin(ids))]\n",
    "id_labels = train_labels_sub.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
    "labels_matrix = np.empty((len(ids), len(labels_names)))\n",
    "\n",
    "for index, id in tqdm(enumerate(ids)):\n",
    "    id_gos_list = id_labels[id]\n",
    "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
    "    labels_matrix[index, temp] = 1\n",
    "\n",
    "labels_list = []\n",
    "for l in range(labels_matrix.shape[0]):\n",
    "    labels_list.append(labels_matrix[l, :])\n",
    "\n",
    "labels_df = pd.DataFrame(data={\"EntryID\":ids, \"labels_vect\":labels_list})\n",
    "labels_df.to_pickle(f\"{WORK_DIR}/train_targets_top\"+str(config.num_labels)+\".pkl\")\n",
    "print(\"GENERATION FINISHED!\")\n",
    "labels_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:04:13.425971600Z",
     "start_time": "2023-11-13T00:03:26.674597800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Directories for the different embedding vectors :\n",
    "embeds_map = {\n",
    "    \"T5\" : \"t5embeds\",\n",
    "    \"ProtBERT\" : \"protbert-embeddings-for-cafa5\",\n",
    "    \"EMS2\" : \"cafa-5-ems-2-embeddings-numpy\"\n",
    "}\n",
    "\n",
    "# Length of the different embedding vectors :\n",
    "embeds_dim = {\n",
    "    \"T5\" : 1024,\n",
    "    \"ProtBERT\" : 1024,\n",
    "    \"EMS2\" : 1280\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:04:13.433113200Z",
     "start_time": "2023-11-13T00:04:13.428970900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      EntryID                                              embed  \\\n0      P20536  [0.04948842525482178, -0.03293515741825104, 0....   \n1      O73864  [-0.04461636394262314, 0.06492499262094498, -0...   \n2      O95231  [-0.02012803591787815, -0.04977943375706673, 0...   \n3  A0A0B4J1F4  [-0.00751461973413825, 0.06062775477766991, 0....   \n4      P54366  [0.013468174263834953, 0.04151567816734314, 0....   \n5      P33681  [0.001116646104492247, -0.01536268275231123, 0...   \n6      P77596  [0.03678780049085617, 0.052980050444602966, 0....   \n7      Q16787  [0.007108339574187994, 0.01562744379043579, 0....   \n8      Q59VP0  [-0.006104866974055767, -0.026720179244875908,...   \n9      P13508  [-0.0071898759342730045, -0.02323203906416893,...   \n\n                                         labels_vect  \n0  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...  \n1  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...  \n2  [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...  \n3  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...  \n4  [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...  \n5  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n6  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n7  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...  \n8  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n9  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>embed</th>\n      <th>labels_vect</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P20536</td>\n      <td>[0.04948842525482178, -0.03293515741825104, 0....</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>O73864</td>\n      <td>[-0.04461636394262314, 0.06492499262094498, -0...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>O95231</td>\n      <td>[-0.02012803591787815, -0.04977943375706673, 0...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A0B4J1F4</td>\n      <td>[-0.00751461973413825, 0.06062775477766991, 0....</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P54366</td>\n      <td>[0.013468174263834953, 0.04151567816734314, 0....</td>\n      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>P33681</td>\n      <td>[0.001116646104492247, -0.01536268275231123, 0...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>P77596</td>\n      <td>[0.03678780049085617, 0.052980050444602966, 0....</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Q16787</td>\n      <td>[0.007108339574187994, 0.01562744379043579, 0....</td>\n      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Q59VP0</td>\n      <td>[-0.006104866974055767, -0.026720179244875908,...</td>\n      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>P13508</td>\n      <td>[-0.0071898759342730045, -0.02323203906416893,...</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ProteinSequenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datatype, embeddings_source):\n",
    "        super(ProteinSequenceDataset).__init__()\n",
    "        self.datatype = datatype\n",
    "\n",
    "        if embeddings_source in [\"ProtBERT\", \"EMS2\"]:\n",
    "            embeds = np.load(f\"{MAIN_DIR}\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeddings.npy\")\n",
    "            ids = np.load(f\"{MAIN_DIR}/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n",
    "\n",
    "        if embeddings_source == \"T5\":\n",
    "            embeds = np.load(f\"{MAIN_DIR}/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeds.npy\")\n",
    "            ids = np.load(f\"{MAIN_DIR}/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n",
    "\n",
    "        embeds_list = []\n",
    "        for l in range(embeds.shape[0]):\n",
    "            embeds_list.append(embeds[l,:])\n",
    "        self.df = pd.DataFrame(data={\"EntryID\": ids, \"embed\" : embeds_list})\n",
    "\n",
    "        if datatype==\"train\":\n",
    "            df_labels = pd.read_pickle(\n",
    "                f\"{WORK_DIR}/train_targets_top\"+str(config.num_labels)+\".pkl\")\n",
    "            self.df = self.df.merge(df_labels, on=\"EntryID\")\\\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        embed = torch.tensor(self.df.iloc[index][\"embed\"], dtype=torch.float32)\n",
    "\n",
    "        if self.datatype==\"train\":\n",
    "            targets = torch.tensor(self.df.iloc[index][\"labels_vect\"], dtype=torch.float32)\n",
    "            return embed, targets\n",
    "\n",
    "        if self.datatype==\"test\":\n",
    "            id = self.df.iloc[index][\"EntryID\"]\n",
    "            return embed, id\n",
    "\n",
    "\n",
    "dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source=\"T5\")\n",
    "dataset.df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:04:42.075324400Z",
     "start_time": "2023-11-13T00:04:38.745475100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPONENTS FOR FIRST PROTEIN:  \n",
      "EMBEDDINGS VECTOR: \n",
      "  tensor([ 0.0495, -0.0329,  0.0325,  ..., -0.0435,  0.0965,  0.0731]) \n",
      "\n",
      "TARGETS LABELS VECTOR: \n",
      "  tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings, labels = dataset.__getitem__(0)\n",
    "print(\"COMPONENTS FOR FIRST PROTEIN:  \")\n",
    "print(\"EMBEDDINGS VECTOR: \\n \", embeddings, \"\\n\")\n",
    "print(\"TARGETS LABELS VECTOR: \\n \", labels, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:04:42.247602700Z",
     "start_time": "2023-11-13T00:04:42.081847600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_dim, input_dim)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 1000)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(1000, 800)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(800, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:16:03.076042700Z",
     "start_time": "2023-11-13T00:16:03.059043900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        # (batch_size, channels, embed_size)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, dilation=1, padding=1, stride=1)\n",
    "        # (batch_size, 3, embed_size)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # (batch_size, 3, embed_size/2 = 512)\n",
    "        self.conv2 = nn.Conv1d(in_channels=3, out_channels=8, kernel_size=3, dilation=1, padding=1, stride=1)\n",
    "        # (batch_size, 8, embed_size/2 = 512)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # (batch_size, 8, embed_size/4 = 256)\n",
    "        self.fc1 = nn.Linear(in_features=int(8 * input_dim/4), out_features=1024)       # 1024 is better\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=num_classes)                # 1024 is better\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:04:52.537968100Z",
     "start_time": "2023-11-13T00:04:52.518372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(embeddings_source, model_type=\"linear\", train_size=0.9):\n",
    "\n",
    "    train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n",
    "\n",
    "    train_set, val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    if model_type == \"linear\":\n",
    "        model = MultiLayerPerceptron(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "    if model_type == \"conv\":\n",
    "        model = CNN1D(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n",
    "    MultiLabelLoss = torch.nn.BCEWithLogitsLoss()\n",
    "    f1_score = MultilabelF1Score(num_labels=config.num_labels).to(config.device)\n",
    "    n_epochs = config.n_epochs\n",
    "\n",
    "    print(\"BEGIN TRAINING...\")\n",
    "    train_loss_history=[]\n",
    "    val_loss_history=[]\n",
    "\n",
    "    train_f1score_history=[]\n",
    "    val_f1score_history=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"EPOCH \", epoch+1)\n",
    "\n",
    "        ## TRAIN PHASE :\n",
    "        losses, scores = [], []\n",
    "\n",
    "        for embed, targets in tqdm(train_dataloader):\n",
    "            embed, targets = embed.to(config.device), targets.to(config.device)\n",
    "            preds = model(embed)\n",
    "            loss= MultiLabelLoss(preds, targets)\n",
    "\n",
    "            score=f1_score(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            scores.append(score.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"Running Average TRAIN Loss : \", avg_loss)\n",
    "        print(\"Running Average TRAIN F1-Score : \", avg_score)\n",
    "        train_loss_history.append(avg_loss)\n",
    "        train_f1score_history.append(avg_score)\n",
    "\n",
    "        ## VALIDATION PHASE :\n",
    "        losses, scores = [], []\n",
    "\n",
    "        for embed, targets in val_dataloader:\n",
    "            embed, targets = embed.to(config.device), targets.to(config.device)\n",
    "            preds = model(embed)\n",
    "\n",
    "            loss= MultiLabelLoss(preds, targets)\n",
    "            score=f1_score(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            scores.append(score.item())\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"Running Average VAL Loss : \", avg_loss)\n",
    "        print(\"Running Average VAL F1-Score : \", avg_score)\n",
    "        val_loss_history.append(avg_loss)\n",
    "        val_f1score_history.append(avg_score)\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(\"TRAINING FINISHED\")\n",
    "    print(\"FINAL TRAINING SCORE : \", train_f1score_history[-1])\n",
    "    print(\"FINAL VALIDATION SCORE : \", val_f1score_history[-1])\n",
    "\n",
    "    losses_history = {\"train\" : train_loss_history, \"val\" : val_loss_history}\n",
    "    scores_history = {\"train\" : train_f1score_history, \"val\" : val_f1score_history}\n",
    "\n",
    "    return model, losses_history, scores_history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN TRAINING...\n",
      "EPOCH  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:38<00:00, 25.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.14723475045942283\n",
      "Running Average TRAIN F1-Score :  0.0372122754938305\n",
      "Running Average VAL Loss :  0.13460040618000285\n",
      "Running Average VAL F1-Score :  0.0732388557433816\n",
      "\n",
      "\n",
      "EPOCH  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:38<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.13037609190612168\n",
      "Running Average TRAIN F1-Score :  0.0806840056596281\n",
      "Running Average VAL Loss :  0.12976928959999764\n",
      "Running Average VAL F1-Score :  0.09229968850766974\n",
      "\n",
      "\n",
      "EPOCH  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.12601814652001345\n",
      "Running Average TRAIN F1-Score :  0.10553580846685867\n",
      "Running Average VAL Loss :  0.1273318100720644\n",
      "Running Average VAL F1-Score :  0.10245534395133811\n",
      "\n",
      "\n",
      "EPOCH  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.12247991531372784\n",
      "Running Average TRAIN F1-Score :  0.12793126974727487\n",
      "Running Average VAL Loss :  0.12556536103199636\n",
      "Running Average VAL F1-Score :  0.1269398009005402\n",
      "\n",
      "\n",
      "EPOCH  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:38<00:00, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11940935002518939\n",
      "Running Average TRAIN F1-Score :  0.1490349325460273\n",
      "Running Average VAL Loss :  0.12478991903896842\n",
      "Running Average VAL F1-Score :  0.1656294320044773\n",
      "\n",
      "\n",
      "EPOCH  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:38<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11648161369157242\n",
      "Running Average TRAIN F1-Score :  0.16883610393647308\n",
      "Running Average VAL Loss :  0.12283315349902425\n",
      "Running Average VAL F1-Score :  0.15888071632278816\n",
      "\n",
      "\n",
      "EPOCH  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11356009525078517\n",
      "Running Average TRAIN F1-Score :  0.18733627639420622\n",
      "Running Average VAL Loss :  0.12277722804407988\n",
      "Running Average VAL F1-Score :  0.17766014406723635\n",
      "\n",
      "\n",
      "EPOCH  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:39<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.11078822561404802\n",
      "Running Average TRAIN F1-Score :  0.20694158645300242\n",
      "Running Average VAL Loss :  0.12223972473293543\n",
      "Running Average VAL F1-Score :  0.19981384024556195\n",
      "\n",
      "\n",
      "EPOCH  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:37<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.10804230017172588\n",
      "Running Average TRAIN F1-Score :  0.225697842198652\n",
      "Running Average VAL Loss :  0.12107926447476659\n",
      "Running Average VAL F1-Score :  0.19289390676255738\n",
      "\n",
      "\n",
      "EPOCH  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:39<00:00, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.10532545226883817\n",
      "Running Average TRAIN F1-Score :  0.2443946681983702\n",
      "Running Average VAL Loss :  0.12118569076327342\n",
      "Running Average VAL F1-Score :  0.19555765683097498\n",
      "\n",
      "\n",
      "EPOCH  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:38<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.10278876154840767\n",
      "Running Average TRAIN F1-Score :  0.26213499251660055\n",
      "Running Average VAL Loss :  0.12235173602987613\n",
      "Running Average VAL F1-Score :  0.1899410560061889\n",
      "\n",
      "\n",
      "EPOCH  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:45<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.0955655012469549\n",
      "Running Average TRAIN F1-Score :  0.29884027188772205\n",
      "Running Average VAL Loss :  0.12049655084099088\n",
      "Running Average VAL F1-Score :  0.2218874068930745\n",
      "\n",
      "\n",
      "EPOCH  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:43<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09402518882439448\n",
      "Running Average TRAIN F1-Score :  0.31265624215850585\n",
      "Running Average VAL Loss :  0.12038932634251458\n",
      "Running Average VAL F1-Score :  0.23219019560409443\n",
      "\n",
      "\n",
      "EPOCH  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:42<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09323775294896487\n",
      "Running Average TRAIN F1-Score :  0.31946561609829344\n",
      "Running Average VAL Loss :  0.12090857978910208\n",
      "Running Average VAL F1-Score :  0.23499868530780077\n",
      "\n",
      "\n",
      "EPOCH  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:42<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09264155195190475\n",
      "Running Average TRAIN F1-Score :  0.32388603066528715\n",
      "Running Average VAL Loss :  0.12098863634413906\n",
      "Running Average VAL F1-Score :  0.23315525174673116\n",
      "\n",
      "\n",
      "EPOCH  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:43<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09147816256328777\n",
      "Running Average TRAIN F1-Score :  0.3283645241083084\n",
      "Running Average VAL Loss :  0.12178948468395642\n",
      "Running Average VAL F1-Score :  0.2331416399351188\n",
      "\n",
      "\n",
      "EPOCH  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:44<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09134841280860025\n",
      "Running Average TRAIN F1-Score :  0.33016157683197195\n",
      "Running Average VAL Loss :  0.1218437911676509\n",
      "Running Average VAL F1-Score :  0.2335235315508076\n",
      "\n",
      "\n",
      "EPOCH  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:41<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09119998385290523\n",
      "Running Average TRAIN F1-Score :  0.33053151204750375\n",
      "Running Average VAL Loss :  0.1212426704088492\n",
      "Running Average VAL F1-Score :  0.2327583348378539\n",
      "\n",
      "\n",
      "EPOCH  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:41<00:00, 24.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.0911907920172879\n",
      "Running Average TRAIN F1-Score :  0.3310403812836696\n",
      "Running Average VAL Loss :  0.12151907617226243\n",
      "Running Average VAL F1-Score :  0.2337652732219015\n",
      "\n",
      "\n",
      "EPOCH  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:43<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average TRAIN Loss :  0.09119559711331016\n",
      "Running Average TRAIN F1-Score :  0.32997415802040536\n",
      "Running Average VAL Loss :  0.12126484872507197\n",
      "Running Average VAL F1-Score :  0.23377399918224132\n",
      "\n",
      "\n",
      "TRAINING FINISHED\n",
      "FINAL TRAINING SCORE :  0.32997415802040536\n",
      "FINAL VALIDATION SCORE :  0.23377399918224132\n"
     ]
    }
   ],
   "source": [
    "t5_model, t5_losses, t5_scores = train_model(embeddings_source=\"T5\", model_type=\"linear\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:31:19.789993100Z",
     "start_time": "2023-11-13T00:16:08.281846800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ -1.4855,   1.7088,  -2.2316,   2.2157,  -2.4843,   0.8278,  -3.3066,\n          -3.2725,   0.0269,  -3.1543,  -3.0371,  -3.0572,  -0.6454,  -2.1439,\n          -1.9545,  -2.8291,  -0.7007,   1.1102,  -7.0548,  -3.0093,  -6.2653,\n           1.0714,  -6.9721,  -8.4482,   0.5410,   1.2247,   0.9523,  -8.0513,\n           1.3346,  -8.0880,  -4.6504,  -2.7136,  -4.4837,  -3.9857,  -4.5416,\n           1.9451,  -9.1502,  -2.4204,  -1.6871,  -8.8654,  -3.0743,  -6.3700,\n          -6.4304,  -4.8251,  -4.7307,  -4.8045,  -2.7189,  -4.5002,  -3.7952,\n          -3.8876,  -5.1422,  -3.8351,  -3.5897,  -1.0677,  -3.0231,  -8.3917,\n          -7.8392,  -5.4879,  -8.3726,  -9.7010,  -9.7090,  -1.9169,  -8.4747,\n          -1.9222,  -4.1673,   1.3398,  -9.7923,   1.6649,  -4.8670,  -2.3847,\n          -5.4642,   1.4769, -10.2711,  -3.3305,  -5.4673,   1.7708,  -5.9627,\n          -3.8806,  -3.2156,  -5.6886,  -1.5462,  -5.4041,  -9.0860,  -5.3901,\n          -3.0712,  -1.8924,  -7.4603,  -5.2696,  -4.6276,  -4.8088,  -7.2406,\n           1.8837,  -4.7290,  -6.4703,  -6.7220,  -6.7506,  -4.4431,  -8.1576,\n          -7.1511,  -6.5586, -10.0283,  -9.6860,  -8.9569,  -9.1872,   2.5780,\n          -6.7498,  -5.4617,  -0.2416,  -7.2464,  -6.5133,  -7.0594, -11.1686,\n          -4.9327,  -3.4510,  -4.5720,  -4.4828,   1.9538, -10.1143,  -8.3685,\n          -5.0788,  -6.1296,  -8.7840,  -4.5942,  -9.4132,  -3.5267,  -7.4259,\n          -3.5209,  -8.9621,  -6.8605,  -5.2734,  -1.4707,  -1.5168,  -9.4049,\n          -1.6513,  -2.7178,  -7.5334,  -4.3158,  -3.3022, -11.5322,  -3.2116,\n          -3.1146,  -8.9067,  -4.2162,  -3.8867,  -3.2465, -10.8441,  -9.4115,\n          -3.0697, -11.5834, -10.3172,  -5.4367,  -5.5086, -10.4888, -10.5904,\n          -3.9728,  -6.5499,  -7.5948,  -8.4231,  -6.7852,  -8.7858,  -6.7211,\n          -4.2056,  -7.8988,  -8.9839,  -9.5249,  -5.6679,  -7.6152, -12.3884,\n          -3.9801,  -2.6010, -10.4589,  -7.8784,  -2.1526, -17.7833,  -7.2132,\n          -6.5771,  -7.8618, -12.5979,  -6.0939, -10.3359,  -5.3492,  -9.5805,\n          -3.2641, -17.0263,  -8.3040, -10.5508,  -4.5035,  -8.7019,  -1.8208,\n         -11.3785,  -9.1191,  -8.9450,  -2.6953, -14.3207,  -9.5339,  -9.0766,\n          -3.5076,  -9.5459, -13.3617,  -6.8780,  -9.7608,  -7.1149,  -7.1817,\n          -3.4547,  -4.7045,  -9.6932, -12.9442,  -4.9987,  -9.3725,  -5.9141,\n          -5.3741,  -9.9961,  -6.6801,  -5.2545,  -6.1095, -10.1030,  -6.5268,\n          -6.7446,  -9.8475,  -6.7672,  -7.4872,  -9.7697,  -8.3730, -11.6761,\n          -3.8327, -13.7614,  -4.9334,  -5.3322,  -7.1561,  -6.8840, -12.3797,\n         -10.5447,  -9.2967, -10.5518, -11.4546,  -7.1667,  -5.9421,  -9.8254,\n         -10.9564,  -1.9817,  -6.4369, -11.6404,  -2.4257,  -4.1741,  -5.8185,\n          -9.8050,  -3.3793,  -7.1924, -13.0929,  -5.9030, -11.5568,  -7.6876,\n         -12.2750,  -7.2104,  -9.7279,  -9.7345,  -7.1632, -12.5180, -11.5373,\n          -7.4892,  -9.3804, -10.4067,  -9.0443,  -6.8703, -11.4862,  -8.4847,\n          -7.0043, -13.3534,  -6.9576,  -8.1893,  -9.4831, -11.2099, -11.0619,\n          -9.3658,  -6.5704,  -7.8292, -13.7561,  -6.2209,  -5.9205,  -7.7163,\n          -7.9320, -11.4090,  -8.3189,  -1.9854,  -8.2358,  -3.3649,  -5.3191,\n          -8.5722, -13.2931, -16.6697, -10.5582,  -9.9473, -11.2252,  -6.8547,\n          -4.9024,  -9.1797,  -6.1302, -13.5639,  -8.0925,  -6.3934, -15.4387,\n          -8.5308,  -9.4107,  -7.3390, -10.4702,  -7.2079,  -6.3412,  -5.7174,\n           2.7474,  -9.2263,  -7.0565,  -9.4544,  -1.8969,  -5.0001,  -8.9059,\n         -10.7455,  -6.5157, -11.1103,  -9.4092,  -5.9799,  -4.5855, -10.9810,\n          -3.4392, -11.4340,  -7.0318, -11.2784, -10.1622, -11.0583,  -8.0801,\n          -6.7338,  -5.8284,  -4.9269,  -3.8125,  -6.6546,  -3.1208,  -7.6076,\n          -7.7040, -17.6451, -14.6182, -11.3493,  -6.6300,  -7.5260,  -7.8785,\n         -16.0047, -10.1449,  -7.7441, -10.7242,  -5.6845,  -8.0623, -12.3164,\n         -11.3287,  -7.5867, -19.2454,  -8.4198,  -8.2974, -10.0135,  -5.6696,\n         -10.3010,  -1.7429,  -7.4968, -10.1917,  -6.2425, -10.4835,  -7.0870,\n         -15.2359,  -8.3364,  -9.8070, -10.8464,  -0.8234,  -7.3130, -10.9312,\n          -4.3863,  -6.9217,  -7.3410, -15.2055, -15.4811, -12.7802, -15.2204,\n         -11.5385, -12.4149, -10.0595,  -7.3731, -12.9138, -10.2727, -10.1700,\n          -4.2806, -15.2300, -17.6416,  -9.4184,  -6.6452, -10.1400,  -6.2504,\n           1.5746,  -7.4217, -12.9497,  -9.9854, -18.6622, -10.0146,  -6.2214,\n          -7.9711,  -6.8384,  -8.8403,  -8.2581, -11.5248,  -4.1219, -14.4678,\n         -16.0022, -10.8223, -11.5872, -11.8717, -11.1784, -13.8343,  -6.9603,\n          -6.9366,  -9.6577,  -7.1605,  -9.4633,  -9.0715, -12.5605,  -6.0276,\n         -15.4241, -10.6188, -22.4877,  -5.9066, -10.4967, -12.7926,  -8.5757,\n         -19.5031,  -6.7969,  -9.4260, -11.7193, -11.2509,  -7.4176, -13.6880,\n         -15.4380,  -9.4740,  -5.8215,  -5.0505, -15.9608,  -7.3044,  -3.7155,\n         -17.7676,  -8.2369,  -4.6282,  -9.6729,  -9.5544,  -7.3754, -13.6103,\n          -5.8704,  -8.7650,  -4.7268,  -5.0882,  -6.5741,  -7.4026,  -9.2961,\n         -11.7395, -10.4334,  -8.2007, -10.2817,  -6.3955, -11.4938, -10.3793,\n          -4.1961, -12.0783, -14.0663, -10.2235,  -7.2415,  -7.6906,  -7.1082,\n          -9.3684, -13.4628,  -4.6030, -12.5200,  -6.5710,  -6.7556, -15.7148,\n          -5.7744,  -3.7626,  -5.9537, -17.1478,  -8.9097, -17.2548,  -8.9584,\n         -16.9996,  -5.1459, -15.6008, -12.0911,  -6.5629, -13.7023, -10.9145,\n          -4.7717, -11.3554, -17.3960, -10.4095,  -7.0985,  -4.9960,  -4.4564,\n          -5.1146, -11.6741, -10.4697]], device='cuda:0',\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_model(dataset[0][0].reshape(1, -1).to(config.device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:33:02.291376700Z",
     "start_time": "2023-11-13T00:33:02.143755300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(embeddings_source):\n",
    "    test_dataset = ProteinSequenceDataset(datatype=\"test\", embeddings_source = embeddings_source)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    if embeddings_source == \"T5\":\n",
    "        model = t5_model\n",
    "    if embeddings_source == \"ProtBERT\":\n",
    "        model = protbert_model\n",
    "    if embeddings_source == \"EMS2\":\n",
    "        model = ems2_model\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n",
    "    top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "    labels_names = top_terms[:config.num_labels].index.values\n",
    "    print(\"GENERATE PREDICTION FOR TEST SET...\")\n",
    "\n",
    "    ids_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n",
    "    go_terms_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n",
    "    confs_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=np.float32)\n",
    "\n",
    "    for i, (embed, id) in tqdm(enumerate(test_dataloader)):\n",
    "        embed = embed.to(config.device)\n",
    "        confs_[i*config.num_labels:(i+1)*config.num_labels] = torch.nn.functional.sigmoid(model(embed)).squeeze().detach().cpu().numpy()\n",
    "        ids_[i*config.num_labels:(i+1)*config.num_labels] = id[0]\n",
    "        go_terms_[i*config.num_labels:(i+1)*config.num_labels] = labels_names\n",
    "\n",
    "    submission_df = pd.DataFrame(data={\"Id\" : ids_, \"GO term\" : go_terms_, \"Confidence\" : confs_})\n",
    "    print(\"PREDICTIONS DONE\")\n",
    "    return submission_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_df = predict(\"T5\")\n",
    "submission_df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Linear_Lightning(pl.LightningModule):\n",
    "    def __init__(self, input_dim, num_classes, train_size, **hparams):\n",
    "        super(Linear_Lightning, self).__init__()\n",
    "\n",
    "        self.model = MultiLayerPerceptron(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n",
    "\n",
    "        train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n",
    "        self.train_set, self.val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n",
    "\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "\n",
    "        self.f1_score = MultilabelF1Score(num_labels=num_classes)\n",
    "        self.accuracy = MultilabelAccuracy(num_labels=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        embed, targets = batch\n",
    "        preds = self(embed)\n",
    "        loss = self.loss_fn(preds, targets)\n",
    "        f1_score = self.f1_score(preds, targets)\n",
    "        acc_score = self.accuracy(preds, targets)\n",
    "\n",
    "        logs = {\"train_loss\" : loss, \"f1_score\" : f1_score, \"accuracy_score\" : acc_score}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"log\": logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        embed, targets = batch\n",
    "        preds = self(embed)\n",
    "        loss= self.loss_fn(preds, targets)\n",
    "        f1_score = self.f1_score(preds, targets)\n",
    "        acc_score = self.accuracy(preds, targets)\n",
    "\n",
    "        return {\"val_loss\": loss, \"f1_score\": f1_score, \"accuracy_score\": acc_score}\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in ouputs]).mean()\n",
    "        logs = {\"val_loss\" : avg_loss}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"avg_val_loss\": avg_loss, \"log\": logs}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataloader = torch.utils.data.DataLoader(self.val_set, batch_size=config.batch_size, shuffle=False,)\n",
    "        return val_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataloader = torch.utils.data.DataLoader(self.train_set, batch_size=self.batch_size, shuffle=False)\n",
    "        return train_dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=config.n_epochs,\n",
    "    limit_train_batches=5000,\n",
    "    logger=logger)\n",
    "\n",
    "model = Linear_Lightning(\n",
    "    input_dim=embeds_dim[embeddings_source],\n",
    "    num_classes=config.num_labels,\n",
    "    train_size=0.8\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
